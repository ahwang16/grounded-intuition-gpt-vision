"Diagram depicting the process of creating a Commonsense Model named COMETdistil from GPT-3. On the upper left corner, there is an illustration of a robot, representing GPT-3 which has 175 billion parameters and is labeled as a General Model. An arrow from GPT-3 points to a funnel for 'Symbolic Knowledge Distillation'. Within this funnel, there's 'CRITiC' labeled as 'Fine-tuned RoBERTa filters for quality' with a robot icon depicting a modified state. A downward arrow leads from this to a representation with oval shapes connected by lines, labeled 'ATOMIC10x', signifying a commonsense knowledge graph with 6.5 million examples. A final downward arrow leads to another robot icon with the text 'COMETdistil' with 1.5 billion parameters representing the final commonsense model."